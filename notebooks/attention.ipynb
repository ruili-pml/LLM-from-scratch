{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7253fc96-277a-493a-adef-cf5ae90325bb",
   "metadata": {},
   "source": [
    "# Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d1e189-8308-4085-8871-c9873c9eaf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0557f",
   "metadata": {},
   "source": [
    "## single-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1814a77-9e74-4173-ada8-bcefbea2893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causal attention score\n",
      "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.3321e-01, 8.6679e-01, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0438e-01, 7.8750e-02, 8.1687e-01, 0.0000e+00],\n",
      "         [1.0947e-16, 1.3340e-19, 2.7633e-15, 1.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [8.7014e-01, 1.2986e-01, 0.0000e+00, 0.0000e+00],\n",
      "         [3.2443e-37, 3.1438e-36, 1.0000e+00, 0.0000e+00],\n",
      "         [9.2693e-02, 1.4553e-02, 5.9197e-25, 8.9275e-01]]])\n"
     ]
    }
   ],
   "source": [
    "### init data\n",
    "B,T,C = 2, 4, 12 # batch, time, channels\n",
    "head_size = 16\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "### define Wq, Wk, Wv\n",
    "k_proj = torch.rand((head_size, C))\n",
    "q_proj = torch.rand((head_size, C))\n",
    "v_proj  = torch.rand((head_size, C))\n",
    "\n",
    "### compute q, k, v\n",
    "k = x @ k_proj.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "q = x @ q_proj.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "v = x @ v_proj.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "\n",
    "### compute attention score\n",
    "attn =  q @ k.transpose(-2, -1) / math.sqrt(head_size)# (B, T, hs) @ (B, hs, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "attn = F.softmax(attn, dim=-1)\n",
    "print(\"causal attention score\")\n",
    "print(attn)\n",
    "\n",
    "### compute output\n",
    "out = attn @ v  # (B, T, T) @ (B, T, hs) -> (B, T, hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7025f",
   "metadata": {},
   "source": [
    "## multi-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3716d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### init data\n",
    "B,T,C = 2, 4, 12 # batch, time, channels\n",
    "head_size = 16\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "########################## Head 1 ##########################\n",
    "### define Wq, Wk, Wv\n",
    "k_proj_1 = torch.rand((head_size, C))\n",
    "q_proj_1 = torch.rand((head_size, C))\n",
    "v_proj_1  = torch.rand((head_size, C))\n",
    "\n",
    "### compute q, k, v\n",
    "k_1 = x @ k_proj_1.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "q_1 = x @ q_proj_1.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "v_1 = x @ v_proj_1.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "\n",
    "### compute attention score\n",
    "attn_1 =  q_1 @ k_1.transpose(-2, -1) / math.sqrt(head_size)# (B, T, hs) @ (B, hs, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn_1 = attn.masked_fill(tril == 0, float('-inf'))\n",
    "attn_1 = F.softmax(attn_1, dim=-1)\n",
    "\n",
    "### compute output\n",
    "out_1 = attn_1 @ v_1  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "\n",
    "########################## Head 1 ##########################\n",
    "### define Wq, Wk, Wv\n",
    "k_proj_2 = torch.rand((head_size, C))\n",
    "q_proj_2 = torch.rand((head_size, C))\n",
    "v_proj_2  = torch.rand((head_size, C))\n",
    "\n",
    "### compute q, k, v\n",
    "k_2 = x @ k_proj_2.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "q_2 = x @ q_proj_2.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "v_2 = x @ v_proj_2.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "\n",
    "### compute attention score\n",
    "attn_2 =  q_2 @ k_2.transpose(-2, -1) / math.sqrt(head_size)# (B, T, hs) @ (B, hs, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn_2 = attn.masked_fill(tril == 0, float('-inf'))\n",
    "attn_2= F.softmax(attn_2, dim=-1)\n",
    "\n",
    "### compute output\n",
    "out_2 = attn_2 @ v_2 # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "\n",
    "########################## fuse multi head ##########################\n",
    "multi_head_proj = torch.rand((head_size, head_size * 2)) # [hs, hs * 2]\n",
    "\n",
    "concat_attention_output = torch.cat([out_1, out_2], dim = -1) # [B, T, hs * 2]\n",
    "\n",
    "multi_head_output = concat_attention_output @ multi_head_proj.T # [B, T, hs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24baf611",
   "metadata": {},
   "source": [
    "# KV-caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96fb09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# hyper‑parameters\n",
    "# ----------------------------------------------------------------------\n",
    "B           = 1        # batch size\n",
    "C           = 12       # input/channel size per token\n",
    "head_size   = 16       # hidden size of our (single) attention head\n",
    "steps       = 10       # how many new tokens to append\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# projection matrices (random for demo)\n",
    "# ----------------------------------------------------------------------\n",
    "k_proj  = torch.randn(head_size, C)\n",
    "q_proj  = torch.randn(head_size, C)\n",
    "v_proj  = torch.randn(head_size, C)\n",
    "next_proj = torch.randn(C, head_size)   # turns last hidden → next x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10b47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# seed context: one initial token vector  (B, 1, C)\n",
    "# ----------------------------------------------------------------------\n",
    "torch.manual_seed(42)\n",
    "x_seq_no_cache = torch.randn(B, 1, C)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# naïve autoregressive loop (no KV cache)\n",
    "# ----------------------------------------------------------------------\n",
    "for t in range(steps):\n",
    "    # 1) project **all** tokens seen so far\n",
    "    k = x_seq_no_cache @ k_proj.T    # (B, T, hs)\n",
    "    q = x_seq_no_cache @ q_proj.T    # (B, T, hs)    \n",
    "    v = x_seq_no_cache @ v_proj.T    # (B, T, hs)\n",
    "\n",
    "    # 2) causal attention over the full T×T matrix\n",
    "    T = k.size(1)\n",
    "    attn = q @ k.transpose(-2, -1) / math.sqrt(head_size)  # (B, T, T)\n",
    "    mask = torch.tril(torch.ones(T, T))\n",
    "    attn = attn.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "    # 3) hidden state of the **last** position\n",
    "    out = attn @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "    out_last = out[:, -1, :]    # (B, hs)\n",
    "\n",
    "    # 4) predict next token\n",
    "    x_next = out_last @ next_proj.T # (B, hs) @ (hs, C) -> (B, C)\n",
    "    x_next = x_next.unsqueeze(1) # (B, C) -> (B, 1 ,C)\n",
    "\n",
    "    # 5) append to sequence\n",
    "    x_seq_no_cache = torch.cat([x_seq_no_cache, x_next], dim=1) # (B, T, C) (B, 1, C) -> (B, T+1, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f487c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# seed context and empty KV cache\n",
    "# ----------------------------------------------------------------------\n",
    "torch.manual_seed(42)\n",
    "x_seq_kv_cache = torch.randn(B, 1, C)          # (B, 1, C)  initial token\n",
    "k_cache = torch.zeros(B, 0, head_size)  # (B, 0, hs), tensor([])\n",
    "v_cache = torch.zeros(B, 0, head_size)  # (B, 0, hs), tensor([])\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# KV‑cached autoregressive loop\n",
    "# ----------------------------------------------------------------------\n",
    "for _ in range(steps):\n",
    "    \n",
    "    # 1) project **current** token only\n",
    "    x_step = x_seq_kv_cache[:, -1, :].unsqueeze(1)  # current input token (B,1,C)\n",
    "\n",
    "    k_step = x_step @ k_proj.T     # (B, 1, hs)\n",
    "    q_step = x_step @ q_proj.T     # (B, 1, hs)\n",
    "    v_step = x_step @ v_proj.T     # (B, 1, hs)\n",
    "\n",
    "    # 2) append new key/value to the cache\n",
    "    k_cache = torch.cat([k_cache, k_step], dim=1)  # (B, t, hs)\n",
    "    v_cache = torch.cat([v_cache, v_step], dim=1)  # (B, t, hs)\n",
    "\n",
    "    # 3) causal attention over cached keys (size 1 × (t+1))\n",
    "    attn   = q_step @ k_cache.transpose(-2, -1) / math.sqrt(head_size)\n",
    "        # (B, 1, hs) @ (B, hs, t) -> (B, 1, t)\n",
    "    attn   = F.softmax(attn, dim=-1)              # (B,1,t)\n",
    "\n",
    "    # 4) hidden state for current position\n",
    "    out_last = attn @ v_cache\n",
    "        # (B, 1, t) @ (B, t, hs) -> (B, 1, hs)\n",
    "\n",
    "    # 5) predict next token vector\n",
    "    x_next = out_last @ next_proj.T\n",
    "        # (B, 1, hs) @ (hs, C) -> (B, 1, C)\n",
    "\n",
    "    # 6) append next token to full sequence & advance\n",
    "    x_seq_kv_cache = torch.cat([x_seq_kv_cache, x_next], dim=1)     # (B, t+1, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da451c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(x_seq_no_cache, x_seq_kv_cache)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
