{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7253fc96-277a-493a-adef-cf5ae90325bb",
   "metadata": {},
   "source": [
    "# Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d1e189-8308-4085-8871-c9873c9eaf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0557f",
   "metadata": {},
   "source": [
    "## single-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1814a77-9e74-4173-ada8-bcefbea2893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causal attention score\n",
      "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.7902e-10, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [8.5029e-03, 9.9091e-01, 5.8267e-04, 0.0000e+00],\n",
      "         [2.0480e-06, 3.0020e-10, 1.4393e-05, 9.9998e-01]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.2679e-06, 0.0000e+00, 0.0000e+00],\n",
      "         [1.5599e-11, 1.0883e-07, 1.0000e+00, 0.0000e+00],\n",
      "         [9.7038e-02, 1.7277e-15, 7.7398e-38, 9.0296e-01]]])\n"
     ]
    }
   ],
   "source": [
    "### init data\n",
    "B,T,C = 2, 4, 12 # batch, time, channels\n",
    "head_size = 16\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "### define Wq, Wk, Wv\n",
    "k_proj = torch.rand((head_size, C))\n",
    "q_proj = torch.rand((head_size, C))\n",
    "v_proj  = torch.rand((head_size, C))\n",
    "\n",
    "### compute q, k, v\n",
    "k = x @ k_proj.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "q = x @ q_proj.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "v = x @ v_proj.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "\n",
    "### compute attention score\n",
    "attn =  q @ k.transpose(-2, -1) / math.sqrt(head_size)# (B, T, hs) @ (B, hs, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "attn = F.softmax(attn, dim=-1)\n",
    "print(\"causal attention score\")\n",
    "print(attn)\n",
    "\n",
    "### compute output\n",
    "out = attn @ v  # (B, T, T) @ (B, T, hs) -> (B, T, hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7025f",
   "metadata": {},
   "source": [
    "## multi-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3716d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### init data\n",
    "B,T,C = 2, 4, 12 # batch, time, channels\n",
    "head_size = 16\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "########################## Head 1 ##########################\n",
    "### define Wq, Wk, Wv\n",
    "k_proj_1 = torch.rand((head_size, C))\n",
    "q_proj_1 = torch.rand((head_size, C))\n",
    "v_proj_1  = torch.rand((head_size, C))\n",
    "\n",
    "### compute q, k, v\n",
    "k_1 = x @ k_proj_1.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "q_1 = x @ q_proj_1.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "v_1 = x @ v_proj_1.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "\n",
    "### compute attention score\n",
    "attn_1 =  q_1 @ k_1.transpose(-2, -1) / math.sqrt(head_size)# (B, T, hs) @ (B, hs, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn_1 = attn.masked_fill(tril == 0, float('-inf'))\n",
    "attn_1 = F.softmax(attn_1, dim=-1)\n",
    "\n",
    "### compute output\n",
    "out_1 = attn_1 @ v_1  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "\n",
    "########################## Head 2 ##########################\n",
    "### define Wq, Wk, Wv\n",
    "k_proj_2 = torch.rand((head_size, C))\n",
    "q_proj_2 = torch.rand((head_size, C))\n",
    "v_proj_2  = torch.rand((head_size, C))\n",
    "\n",
    "### compute q, k, v\n",
    "k_2 = x @ k_proj_2.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "q_2 = x @ q_proj_2.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "v_2 = x @ v_proj_2.T   # (B, T, C) @ (C, hs) -> (B, T, hs)\n",
    "\n",
    "### compute attention score\n",
    "attn_2 =  q_2 @ k_2.transpose(-2, -1) / math.sqrt(head_size)# (B, T, hs) @ (B, hs, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn_2 = attn.masked_fill(tril == 0, float('-inf'))\n",
    "attn_2= F.softmax(attn_2, dim=-1)\n",
    "\n",
    "### compute output\n",
    "out_2 = attn_2 @ v_2 # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "\n",
    "########################## fuse multi head ##########################\n",
    "multi_head_proj = torch.rand((head_size, head_size * 2)) # [hs, hs * 2]\n",
    "\n",
    "concat_attention_output = torch.cat([out_1, out_2], dim = -1) # [B, T, hs * 2]\n",
    "\n",
    "multi_head_output = concat_attention_output @ multi_head_proj.T # [B, T, hs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
