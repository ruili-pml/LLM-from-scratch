{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d482d5e0-b1f8-479f-be26-e4c43190d72e",
   "metadata": {},
   "source": [
    "# Next-token prediction\n",
    "\n",
    "Not sure if this is how data is being prepared in actual training, but as a toy example, we can chop out different parts of a sentence, and then ask it to predict the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5134f09b-9b35-4d96-89bb-e2455fcff506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters in the inputs:\n",
      " !',-.:;?ABCEFHILMNORSTUVWYabcdefghijklmnoprstuvwyz\n",
      "voab size 52\n"
     ]
    }
   ],
   "source": [
    "# load inputs\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text[:3000]\n",
    "\n",
    "# get all the unique characters in the input\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"Unique characters in the inputs:\" + ''.join(chars))\n",
    "print(f\"voab size {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f525c5-2c59-4c65-baf3-24dba1e991c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 36, 36, 1, 46, 35, 32, 44, 32]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {char : i for i, char in enumerate(chars)}\n",
    "int_to_char = {i: char for i, char in enumerate(chars)}\n",
    "\n",
    "def encode(input_string):\n",
    "    return [char_to_int[char] for char in input_string]\n",
    "\n",
    "def decode(input_list):\n",
    "    decoded_chars = [int_to_char[idx] for idx in input_list]\n",
    "    return \"\".join(decoded_chars)\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be6c655-bf1e-453c-bc7d-43d195627b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence tensor([14, 36, 44, 45, 46,  1, 12, 36])\n",
      "for input tensor([14]), target is 36\n",
      "for input tensor([14, 36]), target is 44\n",
      "for input tensor([14, 36, 44]), target is 45\n",
      "for input tensor([14, 36, 44, 45]), target is 46\n",
      "for input tensor([14, 36, 44, 45, 46]), target is 1\n",
      "for input tensor([14, 36, 44, 45, 46,  1]), target is 12\n",
      "for input tensor([14, 36, 44, 45, 46,  1, 12]), target is 36\n",
      "for input tensor([14, 36, 44, 45, 46,  1, 12, 36]), target is 46\n"
     ]
    }
   ],
   "source": [
    "# tokenise input\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "\n",
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n: ]\n",
    "\n",
    "# set up context length\n",
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "print(f\"input sequence {x}\")\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"for input {context}, target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b36456d-18e4-41bf-9930-c3b18ac9bceb",
   "metadata": {},
   "source": [
    "# Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253fc96-277a-493a-adef-cf5ae90325bb",
   "metadata": {},
   "source": [
    "## single-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d1e189-8308-4085-8871-c9873c9eaf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdab17b-2fdb-4f3f-b850-3756f5589e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C = 4,6,12 # batch, time, channels\n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1814a77-9e74-4173-ada8-bcefbea2893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [2.6346e-01, 7.3654e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [3.9511e-01, 2.9510e-01, 3.0979e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [3.4207e-01, 2.9953e-02, 8.3407e-02, 5.4457e-01, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [1.8838e-01, 7.1301e-02, 2.1903e-02, 6.2837e-01, 9.0044e-02,\n",
      "          0.0000e+00],\n",
      "         [1.3378e-01, 2.0116e-01, 1.4047e-01, 1.2868e-01, 1.3532e-01,\n",
      "          2.6059e-01]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [8.3133e-01, 1.6867e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [2.5852e-01, 4.2375e-01, 3.1773e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [4.1047e-01, 3.1722e-01, 2.4141e-01, 3.0894e-02, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [2.2129e-01, 7.2234e-01, 4.5479e-02, 7.5519e-03, 3.3372e-03,\n",
      "          0.0000e+00],\n",
      "         [9.3060e-02, 1.2183e-01, 1.2997e-01, 3.4213e-02, 1.0074e-01,\n",
      "          5.2019e-01]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [1.4840e-01, 8.5160e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [1.0345e-01, 9.3569e-04, 8.9562e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [2.1424e-02, 1.8611e-01, 7.0744e-01, 8.5024e-02, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9994e-02, 5.5390e-01, 2.3654e-02, 4.8046e-02, 2.7440e-01,\n",
      "          0.0000e+00],\n",
      "         [1.2396e-01, 2.5209e-01, 2.8220e-01, 1.7743e-01, 1.1419e-01,\n",
      "          5.0130e-02]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [8.7128e-01, 1.2872e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [1.1166e-01, 7.0347e-01, 1.8488e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [1.6260e-01, 4.6726e-01, 4.4477e-02, 3.2567e-01, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [3.4257e-01, 5.3449e-02, 4.0609e-02, 4.9212e-01, 7.1252e-02,\n",
      "          0.0000e+00],\n",
      "         [1.1453e-01, 5.5067e-02, 3.6711e-02, 7.4265e-01, 2.6896e-02,\n",
      "          2.4146e-02]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(wei)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a445b3-ac9e-4a03-9e22-0d60b47255a2",
   "metadata": {},
   "source": [
    "## fast vs slow implementation\n",
    "\n",
    "```\n",
    "# --------------------------------------------------------------------------\n",
    "# Layout of the “big” QKV weight matrix expected by each implementation\n",
    "#\n",
    "#   ┌───────────── slow path (“hand-rolled” heads) ────────────────┐\n",
    "#   │      Head 1     |      Head 2     |     …    |     Head H    │\n",
    "#   │    Q1  K1  V1   |    Q2  K2  V2   |     …    |   QH  KH  VH  │\n",
    "#   └──────────────────────────────────────────────────────────────┘\n",
    "\n",
    "#\n",
    "#   ┌──────── fast path (CausalSelfAttention.c_attn) ─────────┐\n",
    "#   │       ALL Q       │        ALL K       │       ALL V    │\n",
    "#   │    Q1 Q2 …  QH    |    K1 K2  …  KH    |  V1 V2  … VH   │     \n",
    "#   └─────────────────────────────────────────────────────────┘\n",
    "# --------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class SingleHeadCausalAttention(nn.Module):\n",
    "    def __init__(self, config, keep_bias_term = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = int(config.n_embd / config.n_head)\n",
    "        \n",
    "        self.q_proj = nn.Linear(config.n_embd, self.dim, bias = keep_bias_term)\n",
    "        self.v_proj = nn.Linear(config.n_embd, self.dim, bias = keep_bias_term)\n",
    "        self.k_proj = nn.Linear(config.n_embd, self.dim, bias = keep_bias_term)\n",
    "        \n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size)))\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, C = x.size()\n",
    "        \n",
    "        q = self.q_proj(x) # [B, T, hs]\n",
    "        k = self.k_proj(x) # [B, T, hs]\n",
    "        v = self.v_proj(x) # [B, T, hs]\n",
    "        \n",
    "        att =  q @ k.transpose(1, 2) * (1.0 / math.sqrt(self.dim))\n",
    "            # [B, T, T] i-th row, the weights for token i\n",
    "        att = att.masked_fill(self.bias[:T, :T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim = -1) # softmax for each row\n",
    "        \n",
    "        z = att @ v # [B, T, hs]\n",
    "        \n",
    "        return z\n",
    "\n",
    "class MultiHeadCausalAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, keep_bias_term = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.multi_head_attention = nn.ModuleList([SingleHeadCausalAttention(config,keep_bias_term) for _ in range(config.n_head)])\n",
    "        \n",
    "        self.multi_head_projection = nn.Linear(config.n_embd, config.n_embd, bias = keep_bias_term)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        concatenaed_multi_head = torch.cat([h(x) for h in self.multi_head_attention], dim = -1)\n",
    "        projected_multi_head = self.multi_head_projection(concatenaed_multi_head)\n",
    "        \n",
    "        return projected_multi_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc2aac-61b5-42f6-b78d-810e642945a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CausalSelfAttention, GPTConfig\n",
    "import torch\n",
    "\n",
    "slow_multi_head_attention = MultiHeadCausalAttention(GPTConfig, keep_bias_term = False)\n",
    "fast_multi_head_attention = CausalSelfAttention(GPTConfig, keep_bias_term = False)\n",
    "\n",
    "\n",
    "all_W_q = torch.cat([single_head.q_proj.weight.data for single_head in slow_multi_head_attention.multi_head_attention], dim=0)\n",
    "all_W_k = torch.cat([single_head.k_proj.weight.data for single_head in slow_multi_head_attention.multi_head_attention], dim=0)\n",
    "all_W_v = torch.cat([single_head.v_proj.weight.data for single_head in slow_multi_head_attention.multi_head_attention], dim=0)\n",
    "\n",
    "concatenate_multihead_qkv = torch.cat([all_W_q, all_W_k, all_W_v], dim = 0)\n",
    "\n",
    "fast_multi_head_attention.c_attn.weight.data = concatenate_multihead_qkv\n",
    "fast_multi_head_attention.c_proj.weight.data = slow_multi_head_attention.multi_head_projection.weight.data\n",
    "\n",
    "\n",
    "B, T, C = 2, 5, GPTConfig.n_embd\n",
    "torch.manual_seed(42)\n",
    "test_input = torch.rand((B, T, C))\n",
    "\n",
    "slow_output = slow_multi_head_attention(test_input)\n",
    "fast_output = fast_multi_head_attention(test_input)\n",
    "\n",
    "torch.testing.assert_close(slow_output, fast_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531ba82-6dc6-416c-84de-1807ea60c038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python generic (scicomp-python-env/2024-01)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
