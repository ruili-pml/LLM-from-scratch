{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d482d5e0-b1f8-479f-be26-e4c43190d72e",
   "metadata": {},
   "source": [
    "# Next-token prediction\n",
    "\n",
    "Not sure if this is how data is being prepared in actual training, but as a toy example, we can chop out different parts of a sentence, and then ask it to predict the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5134f09b-9b35-4d96-89bb-e2455fcff506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters in the inputs:\n",
      " !',-.:;?ABCEFHILMNORSTUVWYabcdefghijklmnoprstuvwyz\n",
      "voab size 52\n"
     ]
    }
   ],
   "source": [
    "# load inputs\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text[:3000]\n",
    "\n",
    "# get all the unique characters in the input\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"Unique characters in the inputs:\" + ''.join(chars))\n",
    "print(f\"voab size {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56f525c5-2c59-4c65-baf3-24dba1e991c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 36, 36, 1, 46, 35, 32, 44, 32]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {char : i for i, char in enumerate(chars)}\n",
    "int_to_char = {i: char for i, char in enumerate(chars)}\n",
    "\n",
    "def encode(input_string):\n",
    "    return [char_to_int[char] for char in input_string]\n",
    "\n",
    "def decode(input_list):\n",
    "    decoded_chars = [int_to_char[idx] for idx in input_list]\n",
    "    return \"\".join(decoded_chars)\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be6c655-bf1e-453c-bc7d-43d195627b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence tensor([14, 36, 44, 45, 46,  1, 12, 36])\n",
      "for input tensor([14]), target is 36\n",
      "for input tensor([14, 36]), target is 44\n",
      "for input tensor([14, 36, 44]), target is 45\n",
      "for input tensor([14, 36, 44, 45]), target is 46\n",
      "for input tensor([14, 36, 44, 45, 46]), target is 1\n",
      "for input tensor([14, 36, 44, 45, 46,  1]), target is 12\n",
      "for input tensor([14, 36, 44, 45, 46,  1, 12]), target is 36\n",
      "for input tensor([14, 36, 44, 45, 46,  1, 12, 36]), target is 46\n"
     ]
    }
   ],
   "source": [
    "# tokenise input\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "\n",
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n: ]\n",
    "\n",
    "# set up context length\n",
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "print(f\"input sequence {x}\")\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"for input {context}, target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b36456d-18e4-41bf-9930-c3b18ac9bceb",
   "metadata": {},
   "source": [
    "# Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85d1e189-8308-4085-8871-c9873c9eaf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbdab17b-2fdb-4f3f-b850-3756f5589e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C = 4,6,12 # batch, time, channels\n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1814a77-9e74-4173-ada8-bcefbea2893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2267, 0.7733, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1453, 0.0978, 0.7569, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4621, 0.3031, 0.1498, 0.0850, 0.0000, 0.0000],\n",
      "         [0.2910, 0.1460, 0.0387, 0.4490, 0.0752, 0.0000],\n",
      "         [0.3131, 0.0760, 0.0189, 0.4623, 0.0210, 0.1087]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3994, 0.6006, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4290, 0.2139, 0.3571, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2089, 0.1884, 0.1905, 0.4122, 0.0000, 0.0000],\n",
      "         [0.1997, 0.2266, 0.3020, 0.0368, 0.2349, 0.0000],\n",
      "         [0.3232, 0.1727, 0.0517, 0.2599, 0.0991, 0.0934]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4163, 0.5837, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3303, 0.2722, 0.3975, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1000, 0.0475, 0.4211, 0.4314, 0.0000, 0.0000],\n",
      "         [0.3084, 0.0833, 0.4488, 0.0983, 0.0612, 0.0000],\n",
      "         [0.2100, 0.0727, 0.3492, 0.1793, 0.0828, 0.1061]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2568, 0.7432, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2561, 0.4163, 0.3276, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2330, 0.2925, 0.1776, 0.2969, 0.0000, 0.0000],\n",
      "         [0.1049, 0.2331, 0.1723, 0.2358, 0.2539, 0.0000],\n",
      "         [0.0968, 0.2150, 0.0831, 0.1102, 0.4527, 0.0421]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# single-head attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(wei)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python generic (scicomp-python-env/2024-01)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
